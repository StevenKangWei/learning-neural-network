{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596793531831",
   "display_name": "Python 3.7.2 64-bit ('env37': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import scipy.special\n",
    "from tqdm import tqdm\n",
    "\n",
    "class NeuralNetwork(object):\n",
    "\n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        self.inodes = input_nodes\n",
    "        self.hnodes = hidden_nodes\n",
    "        self.onodes = output_nodes\n",
    "        self.lr = learning_rate\n",
    "\n",
    "        self.wih = numpy.random.normal(0.0, pow(self.hnodes, -0.5), (self.hnodes, self.inodes))\n",
    "        self.who = numpy.random.normal(0.0, pow(self.onodes, -0.5), (self.onodes, self.hnodes))\n",
    "\n",
    "    def save(self, filename='model.bin'):\n",
    "        import pickle\n",
    "        with open(filename, 'wb') as file:\n",
    "            pickle.dump(self, file)\n",
    "\n",
    "    @classmethod\n",
    "    def loads(cls, filename='model.bin', force=False):\n",
    "        if force:\n",
    "            return cls._loads_model(filename)\n",
    "        import os\n",
    "        if not os.path.exists(filename):\n",
    "            return cls._loads_minst(filename)\n",
    "        modeltime = os.path.getmtime(filename)\n",
    "        booktime = os.path.getmtime(os.path.join(os.getcwd(), 'minst.ipynb'))\n",
    "        if booktime > modeltime:\n",
    "            return cls._loads_minst(filename)\n",
    "        return cls._loads_model(filename)\n",
    "\n",
    "    @classmethod\n",
    "    def _loads_model(cls, filename='model.bin'):\n",
    "        import pickle\n",
    "        try:\n",
    "            with open(filename, 'rb') as file:\n",
    "                return pickle.load(file)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return\n",
    "\n",
    "    @classmethod\n",
    "    def _loads_minst(cls, filename='model.bin'):\n",
    "        import torch\n",
    "        import torchvision\n",
    "        from torchvision import transforms, datasets\n",
    "\n",
    "        root = \"../mnist\"\n",
    "        train_data = datasets.MNIST(\n",
    "            root=root,\n",
    "            train=True,\n",
    "            download=True,\n",
    "            transform=transforms.Compose([transforms.ToTensor()])\n",
    "            ) \n",
    "\n",
    "        test_data = datasets.MNIST(\n",
    "            root=root,\n",
    "            train=False,\n",
    "            download=True,\n",
    "            transform=transforms.Compose([transforms.ToTensor()])\n",
    "            ) \n",
    "\n",
    "        trainset = torch.utils.data.DataLoader(train_data, batch_size=1, shuffle=True)\n",
    "        testset = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=True)\n",
    "\n",
    "        input_nodes = 28 * 28 # image size\n",
    "        hidden_nodes = 100\n",
    "        output_nodes = 10\n",
    "\n",
    "        learning_rate = 0.35\n",
    "\n",
    "        n = cls(input_nodes, hidden_nodes, output_nodes, learning_rate)\n",
    "        n.train_dataset(trainset)\n",
    "        n.test_dataset(testset)\n",
    "        n.save(filename)\n",
    "\n",
    "    def activate_function(self, inputs):\n",
    "        return scipy.special.expit(inputs)\n",
    "\n",
    "    def inverse_activation_function(self, outputs):\n",
    "        return scipy.special.logit(outputs)\n",
    "\n",
    "    def train(self, inputs, targets):\n",
    "        inputs = numpy.array(inputs, ndmin=2).T\n",
    "        targets = numpy.array(targets, ndmin=2).T\n",
    "\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "\n",
    "        hidden_outputs = self.activate_function(hidden_inputs)\n",
    "\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "\n",
    "        final_outputs = self.activate_function(final_inputs)\n",
    "\n",
    "        output_errors = targets - final_outputs\n",
    "\n",
    "        hidden_errors = numpy.dot(self.who.T, output_errors)\n",
    "\n",
    "        self.who += self.lr * numpy.dot(\n",
    "            (output_errors * final_outputs * (1.0 - final_outputs)), \n",
    "            numpy.transpose(hidden_outputs)\n",
    "        )\n",
    "        \n",
    "        self.wih += self.lr * numpy.dot(\n",
    "            (hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), \n",
    "            numpy.transpose(inputs)\n",
    "        )\n",
    "\n",
    "    def train_dataset(self, dataset):\n",
    "        for data in tqdm(dataset):\n",
    "            inputs, results = data\n",
    "\n",
    "            image = inputs[0][0]\n",
    "            result = results[0]\n",
    "            inputs = image.reshape(len(image) ** 2)\n",
    "            \n",
    "            targets = numpy.zeros(self.onodes) + 0.01\n",
    "            targets[int(result)] = 0.99\n",
    "            self.train(inputs, targets)\n",
    "\n",
    "    def test_dataset(self, dataset):\n",
    "        total = len(dataset)\n",
    "        count = 0\n",
    "\n",
    "        for data in tqdm(dataset):\n",
    "            inputs, results = data\n",
    "\n",
    "            image = inputs[0][0]\n",
    "            result = int(results)\n",
    "            inputs = image.reshape(len(image) ** 2)\n",
    "            outputs = self.query(inputs)\n",
    "            if outputs == result:\n",
    "                count += 1\n",
    "\n",
    "        print('\\n', count, total, count / total)\n",
    "\n",
    "\n",
    "    def query(self, inputs):\n",
    "        inputs = numpy.array(inputs, ndmin=2).T\n",
    "\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "\n",
    "        hidden_outputs = self.activate_function(hidden_inputs)\n",
    "\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "\n",
    "        final_outputs = self.activate_function(final_inputs)\n",
    "\n",
    "        outputs = {\n",
    "            index: var[0] for index, var in enumerate(final_outputs)\n",
    "        }\n",
    "        outputs = sorted(outputs.items(), key=lambda e: e[1], reverse=True)[0][0]\n",
    "        return outputs\n",
    "\n",
    "    def backquery(self, targets):\n",
    "        # transpose the targets list to a vertical array\n",
    "        final_outputs = numpy.array(targets, ndmin=2).T\n",
    "        \n",
    "        # calculate the signal into the final output layer\n",
    "        final_inputs = self.inverse_activation_function(final_outputs)\n",
    "\n",
    "        # calculate the signal out of the hidden layer\n",
    "        hidden_outputs = numpy.dot(self.who.T, final_inputs)\n",
    "        # scale them back to 0.01 to .99\n",
    "        hidden_outputs -= numpy.min(hidden_outputs)\n",
    "        hidden_outputs /= numpy.max(hidden_outputs)\n",
    "        hidden_outputs *= 0.98\n",
    "        hidden_outputs += 0.01\n",
    "        \n",
    "        # calculate the signal into the hidden layer\n",
    "        hidden_inputs = self.inverse_activation_function(hidden_outputs)\n",
    "        \n",
    "        # calculate the signal out of the input layer\n",
    "        inputs = numpy.dot(self.wih.T, hidden_inputs)\n",
    "        # scale them back to 0.01 to .99\n",
    "        inputs -= numpy.min(inputs)\n",
    "        inputs /= numpy.max(inputs)\n",
    "        inputs *= 0.98\n",
    "        inputs += 0.01\n",
    "        \n",
    "        return inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n = NeuralNetwork.loads(force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import PIL.ImageOps\n",
    "import matplotlib.image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for path, dirs, files in  os.walk('./images'):\n",
    "    for basename in files:\n",
    "        result = int(basename.split('.')[0])\n",
    "        filename = os.path.abspath(os.path.join(path, basename))\n",
    "        image = Image.open(filename)\n",
    "        image = image.resize((28, 28))\n",
    "        image = image.convert(mode=\"L\")\n",
    "        image = PIL.ImageOps.invert(image)\n",
    "        \n",
    "       \n",
    "        inputs = numpy.array(image) / 255\n",
    "        inputs = inputs.reshape(28 * 28)\n",
    "        inputs[inputs < 0.1] = 0\n",
    "\n",
    "        # plt.imshow(inputs.reshape((28, 28)))\n",
    "        output = n.query(inputs)\n",
    "        print(result, output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = numpy.zeros(n.onodes) + 0.01\n",
    "targets[0] = 0.99\n",
    "\n",
    "inputs = n.backquery(targets)\n",
    "inputs = inputs.reshape((28, 28))\n",
    "plt.imshow(inputs) \n"
   ]
  }
 ]
}